<!DOCTYPE html>
<html lang="en">
  <head>
    <title>NICE Dataset</title>
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="topnav">
      <a href="index.html">NICE</a>
      <div class="topnav-right">
        <a class="active" href="index.html">Home</a>
      </div>
    </div>
    <div class="header">
      <h1>NICE: </h1>
      <h2>Neural Image Commenting Evaluation with an Emphasis on Emotion and Empathy</h2>
      <p></p>
    </div>
    <div class="sidenav">
      <h4>NICE</h4>
      <a href="#Instrction">Instrction</a>
      <a href="#Publications">Publications</a>
      <a href="#ToolsDownload">Data Collection Tools</a>
      <a href="#DataDownload">Dataset Download</a>
      <a href="#External">External Resources</a>
    </div>
    <div class="main">
      <h3 id="Instrction">Instrction</h3>
        <p>
          Emotion and empathy are examples of human qualities lacking in many human-machine 
          interactions. The goal of our work is to generate engaging dialogue grounded in a 
          user-shared image with increased emotion and empathy while minimizing socially 
          inappropriate or offensive outputs. We release the Neural Image Commenting Evaluation 
          (NICE) dataset consisting of almost two million images and their corresponding, 
          human-generated comments, as well as a set of baseline models and over 28,000 human 
          annotated samples. Instead of relying on manually labeled emotions, we also use 
          automatically generated linguistic representations as a source of weakly supervised 
          labels. Based on the annotations, we define two different task settings on the NICE 
          dataset. 
        </p>
      
        <p>
          The NICE dataset consists of over 2M images, and 7M image-comment pairs (English) split
          into training, validation, and testing sets. In this section, we first describe how the 
          dataset was collected, and then present some of its unique characteristics. Our goal is
          to simulate natural comments from humans, which requires a large volume of data. Therefore, 
          we scraped 10 million image-comment pairs from licensed website. Each thread was required 
          to start with an image and contain at least one comment. We applied filters to both the images 
          and comments to remove sensitive content such as adult or pornographic content, racy and gory 
          content, non-English language, ethnic-religious content, and some sensitive content (including 
          people's name, documents invoices, bills, financial reports) or other potentially offensive or 
          contentious material (including inappropriate references to violence, crime and illegal substances).
          After filtering, the number of images of the dataset was reduced to 2,233,926 samples and the number
          of image-comment pairs was reduced to 7,304,680 samples. This filtering was performed with 
          pre-trained classifiers. We believe that this dataset presents a valuable resource for the community.
          Below we highlight some of the properties of the data.
        </p>
        <p>
          Data Cleaning: It took several researchers multiple weeks to remove sensitive content for both image
          and text filtering. For example, we used the ``Microsoft Adult Filtering API'' to 
          remove adult, racy and gory images, we use the ``Detecting image types API'' to remove
          clip art and line drawings, we use the ``Optical Character Recognition (OCR) API'' to remove
          printed or handwritten text from the images, such as photos of license plates or containers with serial
          numbers, as well as from documents invoices, bills, financial reports, articles, and more. We also removed
          peopleâ€™s names, politically sensitive language, ethnic-religious content, or other potentially offensive
          material (including inappropriate references to violence, crime and illegal substances) as the similar
          filter API for language cleaning. The last step of filtering, we make sure that NICE dataset had no more
          than 5 corresponding comments for each image, and there are not more than 6 different dialogue threads 
          for the same image. In NICE-Setting II, after annotation, we filter out image-comments pairs without affect
          feature or dialogue topic from dialogue thread. We will keep cleaning and maintaining it in future.
        </p>
      
         <p>
          Setting I: We define NICE-Setting I as text generation for an image. Formally, 
           the generation task as follows: given an image I, and N comments C1, ..., Cn.
           Systems aim to generate the comment Ck, where k is from 1 to N using the current state
           information S{I, C1,...,Ck-1}$. The state information contains input image feature
           I$ and the comments history (C_1, ..., Ck-1).
         </p>
      
         <p>
          Setting II: We define the NICE-Setting II task as generating comments in response to an image, similar to a 
           dialog response in a social conversation setting in order to maximize user engagement and eventually form 
           long-term, emotional connections with users. We formalize the generation task as follows: each sample of 
           this dataset has an image I, a comment topic H of the whole dialogue, and N comments 
           C1, ..., Cn with corresponding thread affect distribution features A1, ..., An. Systems aim to 
           generate the comment Ck using the current state information {I, H, C1,...,Ck-1|Ak},
           which contains the input image features $\mI_{image}$, comment topic H, and the comments history 
           (C_1, ..., Ck-1), and is conditioned on the affect feature Ak.
         </p>
      <h3 id="Publications">Publications</h3>
        <p>
          The paper for this dataset has been accepted by EMNLP 2021:
          <a href="">EMNLP 2021 version</a>
        </p>
        <p>
          The paper for this dataset has published in NeurIPS20 Human in the loop Dialogue systems:
          <a href="https://sites.google.com/view/hlds-2020/home">NeurIPS 2020 workshop version</a>
        </p>
      <h3 id="ToolsDownload">Download Data Collection Tools</h3>
        <p>
          The data collection and filtering tools can be downloaded with the link below. 
        </p>
        <a href="" class="button">Download Tools</a>
      <h3 id="DataDownload">NICE Dataset Download</h3>
        <p>
          The NICE Dataset can be dowloaded with the link below. Because of copyright concerns, we only provide
          public url links to images in the dataset. Users can acquire images by themselves. 
        </p>
        <p>
          You should complete an end user license agreement (EULA) before accessing the dataset. You can download the EULA from 
          <a href="">here</a>.  
        </p>
        <a href="" class="button">Download NICE Dataset</a>
      <h3 id="External">External Resources</h3>
        <p>
          External researches that use NICE dataset is listed below (The list will be update):
        </p>
        <p>
          <a href="https://github.com/ckzbullbullet/NICE">https://github.com/ckzbullbullet/NICE</a>
        </p>
      
      
      
        
    </div>
  </body>
  <div class="footer">
  <p>&nbsp&nbsp<img src="Microsoft-Research-logo.jpg" alt="Microsoft Research"></p>
  </div> 
</html>
